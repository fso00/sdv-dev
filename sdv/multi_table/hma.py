"""Hierarchical Modeling Algorithms."""

import logging
from copy import deepcopy

import numpy as np
import pandas as pd

from sdv.multi_table.base import BaseMultiTableSynthesizer

LOGGER = logging.getLogger(__name__)


class HMASynthesizer(BaseMultiTableSynthesizer):
    """Hierarchical Modeling Algorithm One.

    Args:
        metadata (dict, str or Metadata):
            Metadata dict, path to the metadata JSON file or Metadata instance itself.
    """

    DEFAULT_SYNTHESIZER_KWARGS = {
        'default_distribution': 'beta',
    }

    def __init__(self, metadata, synthesizer_kwargs=None):
        super().__init__(metadata)
        self._synthesizer_kwargs = synthesizer_kwargs or self.DEFAULT_SYNTHESIZER_KWARGS
        self._table_sizes = {}
        self._max_child_rows = {}
        self._modeled_tables = []
        for table_name in self.metadata._tables:
            self.update_table_parameters(table_name, self._synthesizer_kwargs)

    def _get_extension(self, child_name, child_table, foreign_key):
        """Generate the extension columns for this child table.

        The resulting dataframe will have an index that contains all the foreign key values.
        The values for a given index are generated by flattening a model fitted with
        the child rows with that foreign key value.

        Args:
            child_name (str):
                Name of the child table.
            child_table (pandas.DataFrame):
                Data for the child table.
            foreign_key (str):
                Name of the foreign key field.

        Returns:
            pandas.DataFrame
        """
        table_meta = self._table_synthesizers[child_name].get_metadata()

        extension_rows = []
        foreign_key_values = child_table[foreign_key].unique()
        child_table = child_table.set_index(foreign_key)

        index = []
        scale_columns = None
        for foreign_key_value in foreign_key_values:
            child_rows = child_table.loc[[foreign_key_value]]
            try:
                model = self._synthesizer(table_meta, **self._synthesizer_kwargs)
                model.fit_processed_data(child_rows.reset_index(drop=True))
                row = model._get_parameters()
                row = pd.Series(row)
                row.index = f'__{child_name}__{foreign_key}__' + row.index

                if scale_columns is None:
                    scale_columns = [
                        column
                        for column in row.index
                        if column.endswith('scale')
                    ]

                if len(child_rows) == 1:
                    row.loc[scale_columns] = None

                extension_rows.append(row)
                index.append(foreign_key_value)
            except Exception:
                # Skip children rows subsets that fail
                pass

        return pd.DataFrame(extension_rows, index=index)

    def _get_foreign_keys(self, table_name, child_name):
        foreign_keys = []
        for relation in self.metadata._relationships:
            if table_name == relation['parent_table_name'] and\
               child_name == relation['child_table_name']:
                foreign_keys.append(deepcopy(relation['child_foreign_key']))

        return foreign_keys

    def _get_all_foreign_keys(self, table_name):
        foreign_keys = []
        for relation in self.metadata._relationships:
            if table_name == relation['child_table_name']:
                foreign_keys.append(deepcopy(relation['child_foreign_key']))

        return foreign_keys

    def _extend_table(self, table, tables, table_name):
        """Generate the extension columns for this table.

        For each of the table's foreign keys, generate the related extension columns,
        and extend the provided table.

        Args:
            table (pandas.DataFrame):
                The table to extend.
            tables (dict):
                A dictionary mapping table_name to table data (pandas.DataFrame).
            table_name (str):
                The name of the table.

        Returns:
            pandas.DataFrame:
                The extended table.
        """
        LOGGER.info('Computing extensions for table %s', table_name)
        for child_name in self.metadata._get_child_map()[table_name]:
            if child_name not in self._modeled_tables:
                child_table = self._model_table(child_name, tables)
            else:
                child_table = tables[child_name]

            foreign_keys = self._get_foreign_keys(table_name, child_name)
            for index, foreign_key in enumerate(foreign_keys):
                extension = self._get_extension(child_name, child_table.copy(), foreign_key)
                table = table.merge(extension, how='left', right_index=True, left_index=True)
                num_rows_key = f'__{child_name}__{foreign_key}__num_rows'
                table[num_rows_key] = table[num_rows_key].fillna(0)
                self._max_child_rows[num_rows_key] = table[num_rows_key].max()

        return table

    def _pop_foreign_keys(self, table_data, table_name):
        """Remove foreign keys from the ``table_data``.

        Args:
            table_data (pd.DataFrame):
                The table that contains the ``foreign_keys``.
            table_name (str):
                The name representing the table.

        Returns:
            keyes (dict):
                A dictionary mapping with the foreign key and it's values within the table.
        """
        foreign_keys = self._get_all_foreign_keys(table_name)
        keys = {}
        for fk in foreign_keys:
            keys[fk] = table_data.pop(fk).to_numpy()

        return keys

    @staticmethod
    def _clear_nans(table_data):
        for column in table_data.columns:
            column_data = table_data[column]
            if column_data.dtype in (np.int, np.float):
                fill_value = 0 if column_data.isna().all() else column_data.mean()
            else:
                fill_value = column_data.mode()[0]

            table_data[column] = table_data[column].fillna(fill_value)

    def _model_table(self, table_name, tables):
        """Model the indicated table and its children.

        Args:
            table_name (str):
                Name of the table to model.
            tables (dict):
                Dict of original tables.

        Returns:
            pandas.DataFrame:
                table data with the extensions created while modeling its children.
        """
        LOGGER.info('Modeling %s', table_name)

        table = tables.get(table_name)
        self._table_sizes[table_name] = len(table)

        table = self._extend_table(table, tables, table_name)
        keys = self._pop_foreign_keys(table, table_name)
        self._clear_nans(table)
        LOGGER.info('Fitting %s for table %s; shape: %s', self._synthesizer.__name__,
                    table_name, table.shape)

        self._table_synthesizers[table_name].fit_processed_data(table)

        for name, values in keys.items():
            table[name] = values

        tables[table_name] = table
        self._modeled_tables.append(table_name)

        return table

    def _fit(self, processed_data):
        """Fit this HMA1 instance to the dataset data.

        Args:
            processed_data (dict):
                Dictionary mapping each table name to a preprocessed ``pandas.DataFrame``.
        """
        self._modeled_tables = []
        parent_map = self.metadata._get_parent_map()
        for table_name in processed_data:
            if not parent_map.get(table_name):
                self._model_table(table_name, processed_data)

        LOGGER.info('Modeling Complete')
